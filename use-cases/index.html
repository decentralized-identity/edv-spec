
<!DOCTYPE html>
<html lang="en">
  <head>

    <title>Secure Data Storage Use Cases</title>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Secure Data Storage | Use Cases</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Secure Data Storage Use Cases" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Secure Data Storage Use Cases" />
<meta property="og:description" content="Secure Data Storage Use Cases" />
<link rel="canonical" href="https://identity.foundation/secure-data-store/use-cases" />
<meta property="og:url" content="https://identity.foundation/secure-data-store/use-cases" />
<meta property="og:site_name" content="Secure Data Storage Use Cases" />
<script type="application/ld+json">
{"@type":"WebSite","url":"https://identity.foundation/secure-data-store/use-cases","headline":"Secure Data Storage Use Cases","description":"Secure Data Storage Use Cases","name":"Secure Data Storage Use Cases","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <script
      src="https://www.w3.org/Tools/respec/respec-w3c"
      class="remove"
    ></script>
    <script type="text/javascript" class="remove">

      const respecPagesJson = 
        {
  "name": "sds-use-cases",
  "status": "UNOFFICIAL",
  "latest": "https://identity.foundation/secure-data-store/use-cases",
  "repository": "https://github.com/decentralized-identity/secure-data-store",
  "issues": "https://github.com/decentralized-identity/secure-data-store/issues",
  "group": {
    "name": "Credentials Community Group",
    "url": "https://www.w3.org/community/credentials/",
    "list": "public-credentials",
    "patentUri": "https://www.w3.org/community/about/agreements/cla/"
  },
  "editors": [
    {
      "name": "Orie Steele",
      "url": "https://github.com/OR13",
      "company": "Transmute",
      "companyURL": "http://transmute.industries/"
    }
  ],
  "bibliography": {
    "RDF-DATASET-NORMALIZATION": {
      "title": "RDF Dataset Normalization 1.0",
      "href": "http://json-ld.github.io/normalization/spec/",
      "authors": ["David Longley", "Manu Sporny"],
      "status": "CGDRAFT",
      "publisher": "JSON-LD Community Group"
    },
    "OAUTH_XYZ": {
      "title": "Transactional Authorization",
      "href": "https://oauth.xyz/",
    },
    "MY_DATA_OPERATORS": {
      "title": "My Data Operators",
      "href": "http://mydata.org/operators/",
    },
    "HEALTH_REPORT_USE_CASE": {
      "title": "Health Report Use Case",
      "href": "https://github.com/agropper/secure-data-store/raw/master/diagrams/Health_Report_Use_Case.png",
    },
  }
};

      var respecConfig = {
        // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
        specStatus: respecPagesJson.status,

        // the specification's short name, as in http://www.w3.org/TR/short-name/
        shortName: respecPagesJson.name,

        // if you wish the publication date to be other than today, set this
        // publishDate:  "2009-08-06",

        // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
        // and its maturity status
        // previousPublishDate:  "1977-03-15",
        // previousMaturity:  "WD",
        previousPublishDate: "2020-09-30",
        previousMaturity: "UNOFFICIAL",

        // if there a publicly available Editor's Draft, this is the link
        edDraftURI: respecPagesJson.latest,

        // if this is a LCWD, uncomment and set the end of its review period
        // lcEnd: "2009-08-05",

        // if you want to have extra CSS, append them to this list
        // it is recommended that the respec.css stylesheet be kept
        //extraCSS:             ["spec.css", "prettify.css"],

        // editors, add as many as you like
        // only "name" is required
        editors: respecPagesJson.editors,
    

        // extend the bibliography entries
        //localBiblio: webpayments.localBiblio,
        // group: "w3c/ccg",
        // wg: respecPagesJson.group.name,
        // // URI of the public WG page
        // wgURI: respecPagesJson.group.url,
        // // name (with the @w3c.org) of the public mailing to which comments are due
        // wgPublicList: respecPagesJson.group.list,
        // // URI of the patent status for this WG, for Rec-track documents
        // // !!!! IMPORTANT !!!!
        // // This is important for Rec-track documents, do not copy a patent URI from a random
        // // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
        // // Team Contact.
        // wgPatentURI: respecPagesJson.group.patentUri,

        otherLinks: [
          {
            key: "Source Control",
            data: [
              {
                value: respecPagesJson.repository,
                href: respecPagesJson.repository,
              },
            ],
          },
          {
            key: "Issue Tracker",
            data: [
              {
                value: respecPagesJson.issues,
                href: respecPagesJson.issues,
              },
            ],
          },
        ],

        // URI of the patent status for this WG, for Rec-track documents
        // !!!! IMPORTANT !!!!
        // This is important for Rec-track documents, do not copy a patent URI from a random
        // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
        // Team Contact.
        // wgPatentURI:  "",
        maxTocLevel: 4,
        /*preProcess: [ webpayments.preProcess ],
        alternateFormats: [ {uri: "diff-20111214.html", label: "diff to previous version"} ],
        */
        localBiblio: respecPagesJson.bibliography,
      };
    </script>
  </head>
  <body>
    <section id="abstract">
  <p>
    Your specification abstract goes here.
  </p>
</section>

<section id="sotd">
  <p>
    This is an experimental specification and is undergoing regular
    revisions. It is not fit for production deployment.
  </p>
</section>

<section>
  <h2>Use Cases and Requirements</h2>
  <p>
    The purpose of this document is to collect use cases, 
    deployment scenarios, requirements, and design goals 
    in a document in order to guide the work of the DIF SDS WG. 
    At present, we are collecting information. 
    After the information gathering phase, we will go through a 
    ranked choice vote in order to prioritize each use case, 
    scenario, requirement, and design goals.
  </p>
</section>

<section>
<h2>Functional Requirements</h2>

<p>
The following four use cases have been identified as 
representative of common usage patterns (though are by no means the only ones).
</p>
<h3> Store and use data </h3>

<p>
I want to store my information in a safe location. I don't want the storage
provider to be able to see any data I store. This means that only I can see and
use the data. I don’t even want the storage provider to be able to see metadata
like file names, file sizes, directory topology, or who I’ve granted access to
something.
</p>

<h3>Search data </h3>

<p>
Over time, I will store a large amount of data. I want to search the data, but
don't want the service provider to know what I'm storing or searching for.  
</p>

<h3>Share data with one or more entities </h3>

<p>
I want to share my data with other people and services. I can decide on giving
other entities access to data in my storage area when I save the data for the
first time or in a later stage. The storage should only give access to others
when I have explicitly given consent for each item.  
</p>


<p>
I want to be able to revoke the access of others at any time. When sharing data,
I can include an expiration date for the access to my data by a third-party.     
</p>

<h3>Replication - Store the same data in more than one place </h3>

<p>
I want to back up my data across multiple storage locations in case one fails.
These locations can be hosted by different storage providers and can be
accessible over different protocols. One location could be local on my phone,
while another might be cloud-based. The locations should be able to masterless
synchronize between each other so data is up to date in both places regardless
of how I create or update data, and this should happen automatically and without
my help as much as possible.
</p>


<h3>Backup / Disaster Recovery </h3>

<p>
Alice sets up replication to a backup instance so that she does not lose her
data in case her primary instance is damaged/lost etc.     
</p>

<ul>
    <li>
        Replication for purposes of data backup
    </li>
    <li>
        Either involves periodic full-sync replications, or a combination of realtime
    replication and full-syncs.
    </li>
    <li>
        Typically involves unidirectional replication (from an "active" source
        instance to the target backup instance). 
    </li>
</ul>
<h3> Continuous Replication / Replication on Reconnect</h3>

<p>
Alice has multiple instances, and would like to synchronize their contents among
all of them. When her local instance is offline, Alice wants to still be able to
make updates to it. When that instance reconnects, it is expected to hand off
all of the changes that occurred while it was disconnected (and receive changes
from the other instances). This is useful for many different situations:  
</p>

<ul>
    <li>
        Airplane / any other vehicle
    </li>
    <li>
        Sleeping with the phone off
    </li>
    <li>
        Cloud vendor experiences technical difficulties
    </li>
    <li>
        Power outage at home
    </li>
</ul>

<p>Notes</p>

<ul>
    <li>
        A combination of full-sync and realtime replication.
    </li>
    <li>
        Bidirectional replication among two or more instances.
    </li>
    <li>
        Updates to objects can occur at any instance, and are expected to propagate
    to all the other ones.
    </li>
</ul>

<h3> Geographic Availability</h3>

<p>
An organization has two geographically distributed instances. Updates to one
instance are expected to propagate as soon as possible to the other instance. If
one of those goes down, read and write traffic can be redirected to the
remaining one, with minimal interruption in data availability.  
</p>

<ul>
    <li>
        Primarily realtime replication (with fallback to full-sync if connection is
        ever severed).
    </li>
    <li>
        Bidirectional replication among one or more active instances.
    </li>
</ul>

<h3> Alice wants to publish public plaintext about Bob or Carl in a censorship resistant manner.
</h3>

<p>
Alice wants to be able to store data that is plaintext anonymous visible, but
authenticated. Alice does not want anyone to prevent Alice from publishing
public plaintext data.  
</p>

<p>
Alice wants to be able to store plaintext and plaintext metadata on servers that
she does not operate.
</p>


<h3> Enable storage of semantic data and the ability to retrieve it via a self-describing API (based on its schema, type, etc.)
</h3>

<ol>
    <li>
As a user, I want to add schema.org _Offer_ objects so that anyone in the
world can crawl it and create a decentralized app that displays the salable
goods.
    </li>
    <li>
As a developer, I want to create a DID for my code package and publish its
repo/code data as a schema.org _SoftwareSourceCode_ object so anyone can
crawl it and create a decentralized app to visualize packages across the DID-
based ‘DPM’ (think NPM, but decentralized)
    </li>
    <li>
As a business owner, I want to publish various schema-based objects that
define what my business is.
    </li>
</ol>

<h3>Provide a mechanism for receiving and handling a queue of task-based messages. </h3>

<p>
As a user, I would like a mechanism where other entities can send me actionable
message objects that are synced across my SDS instances, so that I can act on
them in whatever way is appropriate for the type of message. If subsequent
messages are exchanged as a result of an initiating message, the subsequent
messages should be referentially tied together (e.g. thread back to the parent).  
</p>

<h3> Alice wants to upload executable code or configuration management that service providers will run based on an event system.
</h3>

<p>
Event Types, Event Subscriptions, Event Handlers, data and program should be
storable in SDS. Similar to systems which watch file changes and transpile, or
forward messages... "IF this THEN that"... could be set of predefined workflows,
or executable code. Examples of similar systems: Github Actions, Zapier, IFTT,
OpenFaaS.    
</p>

<h3> Terminate a relationship with a service provider</h3>

<p>
Ensure users have the ability to terminate a relationship with one or more
service providers in a manner that does not disclose anything about the future
state or location of the user’s data. Ensure the user can verify or obtain a
verifiable certification from service provider that their data has been, if
requested, purged from the provider's system (confirming right to be forgotten).  
</p>

<h3> Sharding data</h3>

<p>
Ensure users have the ability to shard their data, or create M of N key
scenarios across one or multiple providers. Provide options to the user which
allow for either the service provider to manage sharding or allow sharding that
is completely hidden from a service provider.   
</p>

</section>

<section>
<h2>
Focal Use Cases
</h2>

<section>
<h3>Virtual Safe Deposit Box</h3>

<h4>Summary</h4>

<p>Virtual Asset Custody by analogy to safe deposit box in the physical world.
    Intentionally vague about mechanisms of delegation, multisig, authentication,
    and authorization-- should work across multiple version of all those.
</p>

<h4>Assumptions</h4>

<p>Each jurisdiction is different, but Alice is American and Bob works
    for an American bank so we can assume:
</p>
<ul>
<li>Alice is over 18 and has property rights as a legal resident</li>
<li>Proof of identity is required to meet KYC requirements</li>
<li>Bob's bank is an actual bank licensed to offer digital asset custody services</li>
<li>At no point does the bank know the contents of the storage-- it is an encrypted blob</li>
</ul>
<h4> Opening a New Safe Deposit Box </h4>

<p>
    Bank customer Alice has some valuable digital assets (already-encrypted files
    containing blueprints for a missile) that she wants securely put into bank
    custody. She needs to know that the bank cannot access them in clear text. Bank
    manager Bob will be helping her set up her digital "safe deposit box". Alice
    needs to give access to her wife Carroll. Alice authenticates herself (with KYC)
    and signs an agreement for her custodial service, which includes assuming costs
    for key rotations/replacements. Alice also delegates access to Carroll, who is
    also authenticated and KYCed before receiving access as well.
</p>


<h4>Routine Access</h4>

<p>
Once a month, Carroll checks out the contents out for an hour, decrypts them,
sometimes adds or subtracts content before re-encrypting and filing them back
in storage. Each time, she has to be authenticated. These events are timestamped
and logged but otherwise privacy rights are preserved. There may be other
restrictions on access in the contract, by analogy to real-world safe deposit
boxes [1], or arbitrary frictions or delay having to do with relevant banking
regulations [2].
</p>

<h4>Lost Key</h4>

<p>
Due to a severe fire, every electronic copy of Alice's key is lost.
As per the contract, her access (and Carroll's) can be restored for a fee.
</p>

<h4>Divorce with Carroll</h4>

<p>
Carroll's key needs to be revoked without affecting any other aspects or
assumptions. Carroll opens a separate account and places her own assets in it.  
</p>

<h4>Special Agent Dave's Subpoena</h4>

<p>
Special Agent Dave has been investigating Alice's work at the missile plant, and
decides her possession of those blueprints is a criminal act of industrial
espionage. He gets a court order to seize the assets, "drilling into" the
virtual safe deposit box and extract the contents. After this point, Alice
cannot get access to her files, although Dave's court order to get the necessary
key material to decrypt them is out of scope.
</p>

<h4>Bob's intervention due to nonpayment, or incompetence</h4>

<p>
Without her ex's financial support, Carroll cannot stay on top of her banking
bills. As per her contract, after a grace period, the contents are seized and
become property of the bank, auctioned off to pay outstanding dues, encrypted
or not.
</p>

<h4>References</h4>

[1] We can restrict access to your box for any reason, including but not
limited to past due rent and fees, information we receive in court documents,
our inability to obtain information that satisfies our “Know Your Customer”
requirements, and any unexpected circumstances (natural or manmade).
The safe deposit vault will be open during Bank business hours except when access is prevented by reasons beyond our control or  we deem it prudent to deny or limit access.
The bank’s business hours may be changed at any time without notice to you.

(Source: <a href="https://www.chase.com/content/dam/chase-ux/documents/personal/branch-disclosures/safe-deposit-box-lease-agreement.pdf">Chase Safe Deposit Box Lease Agreement</a>,
Source <a href="https://docs.google.com/document/d/1SswHBZ1pwuIUcePeFe8czOoAOaHE78ij4okXuQq5OW0/edit">Draft report from Sovrin Compliance and Payments Task Force</a>
[2]

</section>
<section>

<h3>Steel Material Origins for Auto Parts</h3>

<p>
    The following company names and scenarios are hypothetical.
</p>

<p>
In order to benefit from NAFTA (North American Free Trade Agreement) per revised
rules, auto manufacturers will now be required to demonstrate that seventy
percent of their steel and aluminum purchases originated in North America. They
need to make this information available to regulators and customers, without
providing unnecessary visibility to competitors. US-based steel manufacturer
Steel Inc can generate a mill test report as evidence of steel origins across
all processing steps. This mill report (potentially structured as a verifiable
credential issued by Steel Inc.’s decentralized identifier keys) can be saved in
a secure data store (stored in a discoverable way, one or more locations). Steel
Inc can specify that only keys held by their customer Advanced Automotive, as
well as audit and regulatory bodies in the US Government (like USTR), will be
accepted to decrypt and access the plain text mill certificate data (sharing
with explicit consent). Other parties will be required to request access, which
Steel Inc may choose to provide depending on the audience. Some attributes
included in the mill certificate may be more publicly available, such as the
type of steel product, specification/grade, and location where it was melted and
poured. These data fields are still securely stored with the rest of the mill
certificate, but they do not require authentication to view.
</p>
</section>
<section>



<h3>Perishable Food Recall</h3>

<p>
Super Fresh Market had several customers get sick after consuming a cabbage and
romaine lettuce mix. The company is worried about another E. coli scare and
wants to quickly identify where the product came and what other stores it may be
in. Their staff member Carlos scans a QR code on the salad mix and authenticates
as an employee. After logging in he can see origin and transport details not
available to the general public, such as the fact that the lettuce came from
Sunbright Farms in California, and that it was transported in refrigerated
vehicles the prior week by two different third party logistics providers. Carlos
can reach out to request that these logistics companies provide more detailed
information about their cold storage temperature readings and transit routes.
Given the potential recall situation each logistics company chooses to grant
Carlos access to view this information. Carlos is able to identify a spike in
produce temperature during the final leg of distribution, meaning that product
in three of their stores may be impacted. The salad mix is immediately removed
from the three stores as the investigation continues. In this scenario Carlos,
acting as a Super Fresh Market employee, is already able to authenticate and
view some information in a secure data store. He can also quickly be granted
access to more information based on the urgency of the recall scenario. However
on a daily basis he does not need to see trade route information for logistics
companies, which is typically considered a trade secret.  
</p>

</section>
<section>


<h3>Electronic Medical Records</h3>

<p>by Adrian Gropper, edited by Juan Caballero</p>

<h4>Summary</h4>

<p>
    Note: This is extracted from a longer, more detailed use case including helpful
    flow diagrams and an enrollment section which is stored
    <a href="https://github.com/agropper/secure-data-store/blob/master/COVID-19_Health_Report_Use_Case.md">here</a>
</p>

<p>
Alice’s health report is a short narrative impression of as little as one
session of care signed by Dr. Bob to be presented to her employer and/or filed
in her electronic health record for access by other care providers. Alice's
records are held in trust by a "personal record service" recommended to her by
her local public library. This service consists of an SDS and an authorization
server she uses to access records in that SDS, as well as to grant read and/or
write access to others. This server does not need to use SSI, but it MUST be an
interoperable one she can change for another at any time. (This swappability of
SSI for non-SSI authorization servers may well be a crucial investment in SSI
migration for health records). For the sake of familiarity, we could use UMA as
the server and OAuth as the interoperability standard for this server, but other
forms of prior art might be more relevant in some contexts. [1]   
</p>

<p>
This use case's main virtues for the purposes of the SDS specification is that
it has complex authorization requirements and data privacy requirements, some of
which are best met by having a separation of concerns between authorization and
storage which would ensure maximum prevention of vendor lock-in by ensuring
authorization and storage are separately interchangeable/competitive.
</p>

<h3>Assumptions</h3>

<ul>


<li> Each jurisdiction is different, but Alice is American and Dr. Bob practices
  so-called "direct medicine," meaning he needs direct access to a medical
  record under Alice's control rather than relying on a hospital-based or
  insurer-based medical record.</li>
  <li> A trusted community institution, like a church or community center or, in
  this case, a public library, can operate a privacy-by-default server for
  people like Alice to manage their own health records. See the link above for
  a more detailed use-case about the enrollment/establishment of this small-
  scale trust framework. See also the MyData Operator paper linked in this use
  case's references section [2].</li>
  <li> Alice trusts the Library to recommend a compatible agent and/or secure data
  store. Bob trusts the Library to recommend a mobile wallet for signing health
  records as verified credentials.</li>
  <li> Dr. Bob’s credentials, e.g. a medical license number, are public information
  that should be broadly accessible.</li>
  <li> Public health authorities publish guidelines for a health report that Dr. Bob
  can follow and Alice’s employer accepts as a verifier.</li>
</ul>
<h3>Enrollments (Library, Bob, and Alice)</h3>

<p>
    Note: These steps are clarified greatly with an adoption-oriented flowchart
    included in the longer version of this use case [3].
    
</p>
<p>
Library: The Library installs Issuer/Verifier software and displays a list of
compatible mobile wallets and secure data stores. Secure data stores that enable
**independent choice** of control agent and vice versa are called out as
preferable by the library. For more detail and a flow diagram, see the more
detailed use-case linked from the summary section above.  
</p>

<p>
Dr. Bob installs a mobile identity wallet and is thus able to sign documents,
post timestamps to a public blockchain or other timestamping service, and
satisfy legal retention of documents and signature proofs by sending them to his
secure email address. The Library’s issuer software enables Dr. Bob to
self-assert his medical license and use a public notary to countersign the
credential. The notary’s record can be verified online. Dr. Bob adds his
notarized credential to his mobile wallet.  
</p>

<p>
Alice: Alice uses her mobile phone number to sign up for a secure data store
chosen from the Library’s list. If she doesn’t have one already, Alice receives,
via SMS, a link to her authorization agent as suggested by the secure data store
and picks a password.  
</p>

<h3>Alice seeks Dr. Bob's care</h3> 

<p>
Alice contacts Dr. Bob (out of band), gets various tests and diagnoses (out of
band) and asks Dr. Bob to issue her a health report via the Library Issuer
service for self-sovereign storage and presentation. Dr. Bob accesses an Issuer
service using his credentials, dictates the health report, adds Alice’s SMS
number and signs the report, leaving a timestamp and a proof. Document and proof
are sent to Dr. Bob’s secure email for legal retention. Alice gets an SMS or
secure email from the Library with a link to the   report and proof. Alice
clicks the link which opens as a form on the Library site. Alice enters her
authorization server endpoint onto the form. The Library server contacts Alice’s
authorization server. Alice may have to sign-in. The health report and proof are
sent to Alice’s secure data store. The Library deletes the documents that Dr.
Bob had stored temporarily for Alice. Alice receives an SMS confirmation with a
QR code that links to the document in the secure data store. 
</p>

<h3>Alice presents her health record to an employer</h3>

Alice goes to her employer and displays the QR code in the SMS message. The
employer’s browser takes them to the Library's verifier website. A capability or
authorization issued by Alice MAY be involved in securing the report while it’s
being copied from her data store to the verifier. The Library uses the
capability/token/etc at Alice’s authorization server to get the document and
proof from the secure data store. The library verifies the document for the
employer. [Optional:] The library deletes the document from local storage, if
applicable. If the credential is intended to be presented only once, it may be
revoked by the library.

<h3>Alice migrates SDS without changing authorization server</h3> 

Alice decides to keep her authorization server but use a different secure data
store. Alice opens a new secure data store account and specifies her existing
authorization server as her agent. Alice moves her document from the old store
to the new one. If the employer wants to check Alice’s health report again after
the change, the old QR code points to the same authorization server and a file
that has moved to the new document store. Where it is impossible to persist old
links and references, Alice should at least be notified and have the option to
manually or systematically issue a new QR code.

<h3>Alice migrates SDS without changing authorization server</h3>

<p>
Alice decides to keep her new data store but change the authorization server.
Alice opens a new authorization server account. Alice goes to the new data store
via its current authorization server and specifies her new authorization server.
The employer wants to check Alice’s health report again. The old QR code points
to the old authorization server. Alice has to create a new QR code that points
to the new authorization server. This may need to be a manual operation, but
either way is beyond the scope of this specification.  
</p>

<h3>Follow-up Visit</h3>

<p>
A year later, Dr. Bob wants to see the old report before dictating a new report.
Dr. Bob enters Alice’s SMS into a form at the Library. The Library sends Alice a
message asking for her current authorization server and a request for the old
report. Alice agrees and replies with links to her current authorization server
and to the specific document in question. Dr. Bob, using the Library as a
verifier, presents his credentials to Alice’s authorization server and retrieves
the document.
</p>
</section>

</section>


<section class="informative">

    <h4>
Deployment topologies
    </h4>
    <p>
Based on the use cases, we consider the following deployment topologies:
    </p>
    <ul>
      <li>
<strong>Mobile Device Only:</strong> The server and the client reside on the
same device. The vault is a library providing functionality via a binary API,
using local storage to provide an encrypted database.
      </li>
      <li>
<strong>Mobile Device Plus Cloud Storage:</strong>A mobile device plays the role
of a client, and the server is a remote cloud-based service provider that has
exposed the storage via a network-based API (eg. REST over HTTPS). Data is not
stored on the mobile device.
      </li>
      <li>
<strong>Multiple Devices (Single User) Plus Cloud Storage:</strong> When adding
more devices managed by a single user, the vault can be used to synchronize data
across devices.
      </li>
      <li>
<strong>Multiple Devices (Multiple Users) Plus Cloud Storage:</strong> When
pairing multiple users with cloud storage, the vault can be used to synchronize
data between multiple users with the help of replication and merge strategies.
      </li>
      <li>
<p><strong>Multi-/Cross-cloud:</strong> Some use cases (IoT / machine to machine
/ Skynet / guardianship ) require a non-human or non-functioning actor to
delegate KMS/key control to a cloud vault for oversight or human intervention.
In the case of some Password manager use case architectures or biometrically
accessed/deployed key material storage, as well as some multi-cloud/hybrid-cloud
architectures, key material will need to be retrieved from at least one other
vault before accessing the vault being specified here.</p>

<p>Keys in control of such an entity might still need to securely store signed
credentials or data in a separate vault. Additional diagramming or
specifications will be needed to show how this 2-vault solution could be
constrained to be secure and feasible, even if non-normative.</p>
      </li>
      <li>
<strong>Self-Hosted and/or Home-based Server:</strong> Alice wants to host her
own SDS software instance, on her own server.
      </li>
      <li>
<strong>Support Low Power Devices/Non-private computing:</strong> To support
users without access to private computing resources, the following three
components need to be considered:

<ol>
<li>Secure Storage</li>
<li>Key vault - private key storage and recovery (Key management)</li>
<li>Trusted computing - computational resources which have access to private
keys and plain text private data</li>
</ol>
</li>
    </ul>
  </section>

<section class="informative">
    <h3>
Prior Art
      </h3>

      <h4>
        Peergos
      </h4>
      <p>
        <a href="https://github.com/peergos/peergos">Peergos</a> has many of the same requirements as SDS (actually stronger privacy requirements, especially against a quantum computer) and is built on top of ipfs.
        In summary, its properties include:
        <ul>
          <li>
            global p2p private filesystem
          </li>
          <li>
            strong end to end encryption, and fine grained access control (read only and writable) (capability based, so server's are trustless)
          </li>
          <li>
            data model is hash linked data (IPLD) with updates signed by a keypair
          </li>
          <li>
            hide metadata from server including file names, mime-types, file sizes, directory topology 
          </li>
          <li>
            hide social graph from server (the server cannot see who has been granted access to what)
          </li>
          <li>
            directories are indistinguishable from small files to the server
          </li>
          <li>
            independent of DNS and TLS certificate authorities (though there is a web interface if you trust them)
          </li>
          <li>
            handle arbitrarily large files, including streaming, and O(1) seeking
          </li>
          <li>
            data can be trivially mirrored which provides live redundancy over the ipfs protocol
          </li>
          <li>
            efficient modification of large files without having to re-encrypt the entire file
          </li>
          <li>
            resistant to quantum computer based attacks - unshared files are already fully post-quantum, shared files currently have a limited time window of vulnerability to a large quantum computer
          </li>
          <li>
            access control is done with a version of <a href="https://github.com/Peergos/Peergos/raw/master/papers/wuala-cryptree.pdf">cryptree</a>, improved to fit in the ipfs data model, which is a stunning data structure. More details can be read <a href="https://book.peergos.org/security/cryptree.html">here</a>.
          </li>
          <li>
            all data is in a merkle-champ (compressed hash-array mapped prefix-trie) which is a great data structure for content addressed mutable data, and plays very well with CRDTs as well. The original paper on the CHAMP structure is https://michael.steindorfer.name/publications/oopsla15.pdf. The properties of champs that are useful are insertion order indepdendence (giving a canonical root for a given set of mappings), and balanced structure. 
          </li>
          <li>
            Unshared files are safe from exposure by a large quantum computer (this is because their privacy only relies on hashing and symmetric encryption, neither of which are significantly weakened by a quantum computer). 
          </li>
          <li>
            Peergos servers are trustless. The worst that a malicious server could do is delete your data or withhold valid updates, both of which are easily detected and mitigated by running a mirror. 
          </li>
        </ul>
      More technical descriptions are available <a href="https://book.peergos.org">here</a>
      </p>
    </section>

<section id="conformance">
  <!-- This section is filled automatically by ReSpec. -->
</section>

  </body>
</html>
